{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motifs clustering - Part 2: Motifs DTW distance and clustering\n",
    "\n",
    "Companion notebook of 2_Motifs_analysis. After exporting motifs to csv.gz files, this notebook will be used to calculate a DTW distance between the motifs. You can export this distance matrix as a .csv or an R object file .rds. Optionally, we propose a clustering procedure at the end of the notebook.\n",
    "\n",
    "IMPORTANT:\n",
    "Both the script for computing the distance matrix and performing the clustering are R scripts which will be called directly from the notebook. BEFORE RUNNING THIS NOTEBOOK:\n",
    "1. Make sure that you have a running R installation on your system with the following packages installed: argparse, data.table, proxy, dtw, parallelDist, reshape2, ggplot2, stringr, dendextend\n",
    "2. You will need to manually change the first line in both R scripts: dtw_multivar_distmat.R and pattern_clustering.R. On this line, in both files, change the variable \"user_lib\" such that it contains the path that points to the directory where your personnal R packages are installed. For example in Windows, this library should be under: 'C:/Users/myUserName/Documents/R/win-library/X.X' where X.X is the version of R; in Linux, this library should be under: '/home/myUserName/R/x86_64-pc-linux-gnu-library/X.X'.\n",
    "3. Shall errors arise while running these scripts, the error message will unfortunately not be returned in the notebook but can be seen in the Jupyter console. You can also run these script manually from the command line by copy-pasting the script call created in the notebook (outputted under the notebook cell).\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.filters import threshold_li, threshold_mean\n",
    "import os\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Custom functions/classes\n",
    "path_to_module = '../source'  # Path where all the .py files are, relative to the notebook folder\n",
    "sys.path.append(path_to_module)\n",
    "from load_data import DataProcesser\n",
    "from results_model import top_confidence_perclass, least_correlated_set\n",
    "from pattern_utils import extend_segments, create_cam, longest_segments, extract_pattern\n",
    "from class_dataset import myDataset, ToTensor, RandomCrop\n",
    "\n",
    "# For reproducibility\n",
    "myseed = 7\n",
    "torch.manual_seed(myseed)\n",
    "torch.cuda.manual_seed(myseed)\n",
    "np.random.seed(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for distance matrix with DTW\n",
    "\n",
    "Parameters for DTW:\n",
    "- center_patt: bool, whether to zero-center the motifs. If the input is multivariate, each channel is independently zero-centered. This matters for DTW calculation. Set to True if you don't want the baseline of the signal to be taken into account when computing the DTW distance between the motifs. Note that this will also erase the shift between channels in a multivariate motif.\n",
    "- normalize_dtw: bool, whether to normalize DTW distance to the length of the trajectories. This is important to compare motifs of varying lengths. Set to False only if you have a good reason to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to the same values as in notebook 2, otherwise will cause an error. Should be automatically handled in a further update.\n",
    "min_len_patt = 0\n",
    "max_len_patt = 200\n",
    "\n",
    "# Parameters DTW, see above\n",
    "center_patt = False\n",
    "normalize_dtw = True\n",
    "\n",
    "# Whether to compute a DTW matrix for the motifs of each class and/or one for the motifs of all classes pooled together\n",
    "export_perClass = False\n",
    "export_allPooled = True\n",
    "\n",
    "# Whether to save the distance matrix in csv format and/or in R object format\n",
    "save_csv = True\n",
    "save_rds = True\n",
    "out_dir = 'auto'  # If 'auto' will automatically create a directory to save dtw matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only used to retrieve measurement variables and classes without manual input\n",
    "data_file = '../sample_data/Synthetic_Univariate.zip'\n",
    "# data_file = '../sample_data/GrowthFactor_ErkAkt_Bivariate.zip'\n",
    "\n",
    "meas_var = None  # Set to None for auto detection\n",
    "data = DataProcesser(data_file, datatable=False)\n",
    "classes = tuple(data.classes[data.col_classname])\n",
    "meas_var = data.detect_groups_times()['groups'] if meas_var is None else meas_var\n",
    "\n",
    "# Path where to export tables with motifs\n",
    "if out_dir == 'auto':\n",
    "    out_dir = 'output/' + '_'.join(meas_var) + '/local_motifs/'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the R installation\n",
    "path_to_R = '/usr/bin/Rscript'\n",
    "# Path that point to the directory where the scripts for dtw and clustering are (in this example one up the Notebook one)\n",
    "path_to_Rscripts = os.path.abspath('../source') + os.path.sep\n",
    "path_to_Rscripts = path_to_Rscripts.replace('\\\\', '/')  # for Windows paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build distance matrix with DTW\n",
    "\n",
    "This is done in R with the implementation of the *parallelDist* package. It is very efficient and has support for multivariate cases.\n",
    "\n",
    "The distance matrices can be written both as a compressed csv (squared matrix, lower triangle and diagonal set to Inf) or as an rds R object which contains an R distance object. The latter is very useful to resume clustering directly in R, just load the distance object with readRDS()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building distance matrix for pooled data with call:\n",
      "\"/usr/bin/Rscript\" --vanilla /home/marc/Dropbox/CNN_paper_MarcAntoine/CODEX/source/dtw_multivar_distmat.R -i \"output/FRST/local_motifs/motif_allPooled.csv.gz\" -o \"output/FRST/local_motifs/DTWdist_allPooled\" -l 200 -n 1 --norm T --center F --colid pattID --csv T --rds T\n"
     ]
    }
   ],
   "source": [
    "center_patt = \"T\" if center_patt else \"F\"\n",
    "normalize_dtw = \"T\" if normalize_dtw else \"F\"\n",
    "save_csv = \"T\" if save_csv else \"F\"\n",
    "save_rds = \"T\" if save_rds else \"F\"\n",
    "\n",
    "if export_perClass:\n",
    "    for classe in classes:\n",
    "        print('Building distance matrix for class: {}, with call:'.format(classe))\n",
    "        fin_patt = out_dir + 'motif_{}.csv.gz'.format(classe)\n",
    "        fout_dist = out_dir + 'DTWdist_{}'.format(classe)\n",
    "        call_str = r'\"{}\" --vanilla {}dtw_multivar_distmat.R -i \"{}\" -o \"{}\" -l {} -n {} --norm {} --center {} --colid {} --csv {} --rds {}'.format(\n",
    "                path_to_R,\n",
    "                path_to_Rscripts,\n",
    "                fin_patt,\n",
    "                fout_dist,\n",
    "                max_len_patt,\n",
    "                len(meas_var),\n",
    "                normalize_dtw,\n",
    "                center_patt,\n",
    "                \"NULL\",\n",
    "                save_csv,\n",
    "                save_rds)\n",
    "        print(call_str + '\\n')\n",
    "        subprocess.call(call_str, shell=True)\n",
    "            \n",
    "if export_allPooled:\n",
    "    print('Building distance matrix for pooled data with call:')\n",
    "    fin_patt = out_dir + 'motif_allPooled.csv.gz'\n",
    "    fout_dist = out_dir + 'DTWdist_allPooled'\n",
    "    call_str = r'\"{}\" --vanilla {}dtw_multivar_distmat.R -i \"{}\" -o \"{}\" -l {} -n {} --norm {} --center {} --colid {} --csv {} --rds {}'.format(\n",
    "        path_to_R,\n",
    "        path_to_Rscripts,\n",
    "        fin_patt,\n",
    "        fout_dist,\n",
    "        max_len_patt,\n",
    "        len(meas_var),\n",
    "        normalize_dtw,\n",
    "        center_patt,\n",
    "        \"pattID\",\n",
    "        save_csv,\n",
    "        save_rds)\n",
    "    print(call_str)\n",
    "    subprocess.call(call_str, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster, generate report with results\n",
    "\n",
    "This will use the distance matrix generated in the previous section to perform hierarchical clustering. Medoids from each cluster are reported along with a random sample of each cluster.\n",
    "\n",
    "- nclust: int, number of clusters.\n",
    "- nmedoid: int, number of medoids to plot per cluster.\n",
    "- nseries: int, number of series to plot from each cluster (choosen randomly).\n",
    "- linkage: str, one of [\"ward.D\", \"ward.D2\", \"single\", \"complete\", \"average\", \"mcquitty\", \"median\", \"centroid\"]. Linkage for hierarchical clustering. Ward and average seem to be advisable defaults. More details on the help page for hierarchical clustering with R: https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster patterns for pooled data with call:\n",
      "\"/usr/bin/Rscript\" --vanilla /home/marc/Dropbox/CNN_paper_MarcAntoine/CODEX/source/pattern_clustering.R -d output/FRST/local_motifs/DTWdist_allPooled.csv.gz -p output/FRST/local_motifs/motif_allPooled.csv.gz -o output/FRST/local_motifs/motifPlot_allPooled.pdf -l 200 -n 1 -c 3 -m 8 -t 16 --colid pattID --linkage ward.D\n",
      "Clustering done.\n"
     ]
    }
   ],
   "source": [
    "nclust = 3\n",
    "nmedoid = 8\n",
    "nseries = 16\n",
    "linkage = \"ward.D\"\n",
    "\n",
    "assert linkage in [\"ward.D\", \"ward.D2\", \"single\", \"complete\", \"average\", \"mcquitty\", \"median\", \"centroid\"]\n",
    "\n",
    "if export_perClass:\n",
    "    for classe in classes:\n",
    "        print('Cluster patterns for class: {} with call:'.format(classe))\n",
    "        fin_patt = out_dir + 'motif_{}.csv.gz'.format(classe)\n",
    "        fin_dist = out_dir + 'DTWdist_{}.csv.gz'.format(classe)\n",
    "        fout_plot = out_dir + 'motifPlot_{}.pdf'.format(classe)\n",
    "        call_str = r'\"{}\" --vanilla {}pattern_clustering.R -d {} -p {} -o {} -l {} -n {} -c {} -m {} -t {} --colid {} --linkage {}'.format(\n",
    "           path_to_R,\n",
    "           path_to_Rscripts,\n",
    "           fin_dist,\n",
    "           fin_patt,\n",
    "           fout_plot,\n",
    "           max_len_patt,\n",
    "           len(meas_var),\n",
    "           nclust,\n",
    "           nmedoid,\n",
    "           nseries,\n",
    "           \"NULL\",\n",
    "           linkage)\n",
    "        print(call_str + '\\n')\n",
    "        subprocess.call(call_str, shell=True)\n",
    "\n",
    "if export_allPooled:\n",
    "    print('Cluster patterns for pooled data with call:')\n",
    "    fin_patt = out_dir + 'motif_allPooled.csv.gz'\n",
    "    fin_dist = out_dir + 'DTWdist_allPooled.csv.gz'\n",
    "    fout_plot = out_dir + 'motifPlot_allPooled.pdf'\n",
    "    call_str = r'\"{}\" --vanilla {}pattern_clustering.R -d {} -p {} -o {} -l {} -n {} -c {} -m {} -t {} --colid {} --linkage {}'.format(\n",
    "           path_to_R,\n",
    "           path_to_Rscripts,\n",
    "           fin_dist,\n",
    "           fin_patt,\n",
    "           fout_plot,\n",
    "           max_len_patt,\n",
    "           len(meas_var),\n",
    "           nclust,\n",
    "           nmedoid,\n",
    "           nseries,\n",
    "           \"pattID\",\n",
    "           linkage)\n",
    "    print(call_str)\n",
    "    subprocess.call(call_str, shell=True)\n",
    "print('Clustering done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
